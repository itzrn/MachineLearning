{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4700cd",
   "metadata": {},
   "source": [
    "# Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fc374c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7687d",
   "metadata": {},
   "source": [
    "# Importing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ed578a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Datasets/T03_50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06dee255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0   165349.20       136897.80        471784.10    New York  192261.83\n",
      "1   162597.70       151377.59        443898.53  California  191792.06\n",
      "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3   144372.41       118671.85        383199.62    New York  182901.99\n",
      "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
      "5   131876.90        99814.71        362861.36    New York  156991.12\n",
      "6   134615.46       147198.87        127716.82  California  156122.51\n",
      "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
      "8   120542.52       148718.95        311613.29    New York  152211.77\n",
      "9   123334.88       108679.17        304981.62  California  149759.96\n",
      "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
      "11  100671.96        91790.61        249744.55  California  144259.40\n",
      "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
      "13   91992.39       135495.07        252664.93  California  134307.35\n",
      "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
      "15  114523.61       122616.84        261776.23    New York  129917.04\n",
      "16   78013.11       121597.55        264346.06  California  126992.93\n",
      "17   94657.16       145077.58        282574.31    New York  125370.37\n",
      "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
      "19   86419.70       153514.11             0.00    New York  122776.86\n",
      "20   76253.86       113867.30        298664.47  California  118474.03\n",
      "21   78389.47       153773.43        299737.29    New York  111313.02\n",
      "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
      "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
      "24   77044.01        99281.34        140574.81    New York  108552.04\n",
      "25   64664.71       139553.16        137962.62  California  107404.34\n",
      "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
      "27   72107.60       127864.55        353183.81    New York  105008.31\n",
      "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
      "29   65605.48       153032.06        107138.38    New York  101004.64\n",
      "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
      "31   61136.38       152701.92         88218.23    New York   97483.56\n",
      "32   63408.86       129219.61         46085.25  California   97427.84\n",
      "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
      "34   46426.07       157693.92        210797.67  California   96712.80\n",
      "35   46014.02        85047.44        205517.64    New York   96479.51\n",
      "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
      "37   44069.95        51283.14        197029.42  California   89949.14\n",
      "38   20229.59        65947.93        185265.10    New York   81229.06\n",
      "39   38558.51        82982.09        174999.30  California   81005.76\n",
      "40   28754.33       118546.05        172795.67  California   78239.91\n",
      "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
      "42   23640.93        96189.63        148001.11  California   71498.49\n",
      "43   15505.73       127382.30         35534.17    New York   69758.98\n",
      "44   22177.74       154806.14         28334.72  California   65200.33\n",
      "45    1000.23       124153.04          1903.93    New York   64926.08\n",
      "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
      "47       0.00       135426.92             0.00  California   42559.73\n",
      "48     542.05        51743.15             0.00    New York   35673.41\n",
      "49       0.00       116983.80         45173.06  California   14681.40\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1121b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R&D Spend          0\n",
      "Administration     0\n",
      "Marketing Spend    0\n",
      "State              0\n",
      "Profit             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to know the number of null values present in any column of the dataset\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c0ecd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York      17\n",
      "California    17\n",
      "Florida       16\n",
      "Name: State, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# printing the number of categories in state column\n",
    "print(dataset['State'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f9cc04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into X_features and Y_outcome\n",
    "X_features = dataset.iloc[:, :-1].values\n",
    "Y_outcome = dataset.iloc[:, [-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb33e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_features ->\n",
      " [[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 0.0 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [0.0 135426.92 0.0 'California']\n",
      " [542.05 51743.15 0.0 'New York']\n",
      " [0.0 116983.8 45173.06 'California']]\n"
     ]
    }
   ],
   "source": [
    "# printing the X_features and Y_outcome\n",
    "print(\"X_features ->\\n\",X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ff3dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_outcome ->\n",
      " [[192261.83]\n",
      " [191792.06]\n",
      " [191050.39]\n",
      " [182901.99]\n",
      " [166187.94]\n",
      " [156991.12]\n",
      " [156122.51]\n",
      " [155752.6 ]\n",
      " [152211.77]\n",
      " [149759.96]\n",
      " [146121.95]\n",
      " [144259.4 ]\n",
      " [141585.52]\n",
      " [134307.35]\n",
      " [132602.65]\n",
      " [129917.04]\n",
      " [126992.93]\n",
      " [125370.37]\n",
      " [124266.9 ]\n",
      " [122776.86]\n",
      " [118474.03]\n",
      " [111313.02]\n",
      " [110352.25]\n",
      " [108733.99]\n",
      " [108552.04]\n",
      " [107404.34]\n",
      " [105733.54]\n",
      " [105008.31]\n",
      " [103282.38]\n",
      " [101004.64]\n",
      " [ 99937.59]\n",
      " [ 97483.56]\n",
      " [ 97427.84]\n",
      " [ 96778.92]\n",
      " [ 96712.8 ]\n",
      " [ 96479.51]\n",
      " [ 90708.19]\n",
      " [ 89949.14]\n",
      " [ 81229.06]\n",
      " [ 81005.76]\n",
      " [ 78239.91]\n",
      " [ 77798.83]\n",
      " [ 71498.49]\n",
      " [ 69758.98]\n",
      " [ 65200.33]\n",
      " [ 64926.08]\n",
      " [ 49490.75]\n",
      " [ 42559.73]\n",
      " [ 35673.41]\n",
      " [ 14681.4 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_outcome ->\\n\", Y_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7a8aa17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_features --> <class 'numpy.ndarray'>\n",
      "Y_outcome --> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# checking the datat type of X_features and Y_outcome\n",
    "print(\"X_features -->\", type(X_features))\n",
    "print(\"Y_outcome -->\", type(Y_outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d2902",
   "metadata": {},
   "source": [
    "# Importing OHE, ColumnTranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d9376db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bfd54a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cT = ColumnTransformer(transformers=[\n",
    "    ('OHE', OneHotEncoder(sparse_output=False),[3])\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_features = cT.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44bc0369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# printing the DataType of X_features\n",
    "print(type(X_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b2e7ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_features after OHE ->\n",
      " [[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "# printing X_features after doing categorical encoding\n",
    "print(\"X_features after OHE ->\\n\",X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50486b",
   "metadata": {},
   "source": [
    "we don't have to apply feature scaling. \n",
    "Why? Because you know, in the equation of the Multiple Linear Regression, you know,\n",
    "you have this coefficient that is multiplied to each independent variable, you know, each feature.\n",
    "And, therefore, it doesn't matter that some features have higher values than others,\n",
    "because the coefficients will compensate to put everything on the same scale.\n",
    "And, therefore, remember this, in Multiple Linear Regression, there is absolutely no need\n",
    "to apply feature scaling.\n",
    "\n",
    "Do we need to check the assumptions of linear regression?\n",
    "The answer is absolutely not, because whenever you have a new data set, and you want to experiment with\n",
    "some machinery models to figure out which one leads to the highest accuracy, well,\n",
    "even if your data set doesn't have linear relationships, you can still try\n",
    "a Multiple Linear Regression on it. And, if you know your data set\n",
    "doesn't have linear relationships, well, your Multiple Linear Regression model will just\n",
    "perform poorly, and therefore, it will get an accuracy lower\n",
    "than the accuracies of your other models.\n",
    "So, you will just not select the Multiple Linear Regression model, but you don't have to check\n",
    "the Multiple Linear Regression assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef50f23",
   "metadata": {},
   "source": [
    "# Importing train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af170f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f1ce09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, Y_outcome, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e08e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train -->\n",
      " [[0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]]\n",
      "X_test --> \n",
      " [[0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]]\n",
      "y_train --> \n",
      " [[ 96778.92]\n",
      " [ 96479.51]\n",
      " [105733.54]\n",
      " [ 96712.8 ]\n",
      " [124266.9 ]\n",
      " [155752.6 ]\n",
      " [132602.65]\n",
      " [ 64926.08]\n",
      " [ 35673.41]\n",
      " [101004.64]\n",
      " [129917.04]\n",
      " [ 99937.59]\n",
      " [ 97427.84]\n",
      " [126992.93]\n",
      " [ 71498.49]\n",
      " [118474.03]\n",
      " [ 69758.98]\n",
      " [152211.77]\n",
      " [134307.35]\n",
      " [107404.34]\n",
      " [156991.12]\n",
      " [125370.37]\n",
      " [ 78239.91]\n",
      " [ 14681.4 ]\n",
      " [191792.06]\n",
      " [141585.52]\n",
      " [ 89949.14]\n",
      " [108552.04]\n",
      " [156122.51]\n",
      " [108733.99]\n",
      " [ 90708.19]\n",
      " [111313.02]\n",
      " [122776.86]\n",
      " [149759.96]\n",
      " [ 81005.76]\n",
      " [ 49490.75]\n",
      " [182901.99]\n",
      " [192261.83]\n",
      " [ 42559.73]\n",
      " [ 65200.33]]\n",
      "y_test -->\n",
      " [[103282.38]\n",
      " [144259.4 ]\n",
      " [146121.95]\n",
      " [ 77798.83]\n",
      " [191050.39]\n",
      " [105008.31]\n",
      " [ 81229.06]\n",
      " [ 97483.56]\n",
      " [110352.25]\n",
      " [166187.94]]\n"
     ]
    }
   ],
   "source": [
    "# printing X_train, X_test, y_train, y_test\n",
    "print(\"X_train -->\\n\", X_train)\n",
    "print(\"X_test --> \\n\", X_test)\n",
    "print(\"y_train --> \\n\", y_train)\n",
    "print(\"y_test -->\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86807967",
   "metadata": {},
   "source": [
    "The first question is, do we have to avoid, you know to do something to avoid the dummy variable trap?\n",
    "And the answer is no because indeed the Multiple Linear Regression class that we're about to import\n",
    "and which will build the Multiple Linear Regression model itself and actually also train it\n",
    "because remember that a class actually can complete several actions including building it and training it.\n",
    "And while this class will automatically avoid this trap which means that indeed, you know\n",
    "one of the three first columns here because remember Kyril explained that one is redundant, well, we'll automatically be outcast. So you have nothing to worry about regarding the dummy variable trap,\n",
    "you don't have to remove one of the columns here. And that's the beauty of classes.\n",
    "\n",
    "Now, second question, do we have to work on the features to select the best ones with, you know\n",
    "the techniques that Kyril introduced to you, like, for example, backward elimination.\n",
    "Do we have to deploy the backward elimination technique in order to select the features that have\n",
    "the highest P values and that are the most statistically significant?\n",
    "And the answer is once again, no. Why is that?\n",
    "Well, for the exact same reason as the dummy variable trap. The class that we're about to call\n",
    "to build our Multiple Linear Regression model will automatically identify the best features, you know\n",
    "the features that have the highest P values or that are the most statistically significant\n",
    "to figure out how to predict the dependent variable, you know the profit with the highest accuracy.\n",
    "So once again, you don't have to worry about this. The class of (indistinct), you know\n",
    "this amazing data science library will take care of everything for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab78042",
   "metadata": {},
   "source": [
    "# Importing Multiple Liear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d2bd09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f4a0af87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mLR = LinearRegression()  # we don't have to put any parameter here\n",
    "mLR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31048a9",
   "metadata": {},
   "source": [
    "You know, compared to what we did in the previous section on simple linear regression.\n",
    "This time we actually have several features, right?\n",
    "We actually have four features instead of one, like before.\n",
    "And therefore we cannot actually plot a graph\n",
    "\n",
    "like we did in simple in our regression, where, you know, we have the features and the X axis\n",
    "and the dependent variable and the Y axis, because simply there are four features.\n",
    "We would need actually a five dimensional graph, which is not possible to visualize as humans.\n",
    "\n",
    "So what we're gonna do instead you know, instead of visualizing\n",
    "the test set results on a plot, well we will actually display two vectors.\n",
    "The first one is the vectors of the real profit in the test set.\n",
    "And remember that the test set actually counts for 20% of the whole data set.\n",
    "And therefore since here, there are, you know actually 50 observations corresponding to the 50 startups.\n",
    "Well, 20% of 50 will be 10 observations in the test set. So we will actually have 10 samples in a test set\n",
    "and we will display two vectors. First, a vector of the 10 real profits from the test set.\n",
    "You know, the 10 ground truth. And a second vector of the 10 predicted profits\n",
    "of the same test set so that we can compare for each startup of the test set\n",
    "if our predicted profit is close to the real profit. And that's how we will, you know, evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962902e3",
   "metadata": {},
   "source": [
    "# Predicting The Test Set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0b5cc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mLR.predict(X_test)\n",
    "np.set_printoptions(precision=2) # here precision means->numerical value till two decimal places\n",
    "# the bellow line is printing the predicted value and the test value in two column so we can compare the values\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8782a22",
   "metadata": {},
   "source": [
    "the above values are very close, so we can say the model is good for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e53a73f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.66e+01 -8.73e+02  7.86e+02  7.73e-01  3.29e-02  3.66e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(mLR.coef_)  \n",
    "# this is the way to find all the coefficient of the feature variable in multiLinear Regression equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "066128af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42467.53]\n"
     ]
    }
   ],
   "source": [
    "# this is how we calculate the intercept\n",
    "print(mLR.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
